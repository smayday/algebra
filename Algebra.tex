\documentclass{article}
\title{Algebra Notes}
\author{May Piatt}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\date{February 2024}
%for mathbb stuff
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\newcommand{\vs}{\bigskip\\\text{}}
\usepackage{titlesec}
\titleformat{\subsubsection}[runin]
{\bfseries}{\thesubsubsection}{1em}{}
\newcommand{\beginproof}{\vspace{10pt}\newline\textit{Proof.}\hspace{1em}}

% required for newpx palatino to work

\usepackage{fontaxes}
\usepackage{xstring}
\usepackage{etoolbox}
\usepackage[osf]{newpxtext}

\setcounter{section}{-1}
\setcounter{tocdepth}{2}

\begin{document}
\maketitle
\tableofcontents
\section{Lecture 0}
\subsection{Direct Sums} The construction that's going to be the most useful for
us is direct sums. Let $R$ be a ring and $M_i$ for $i \in I$ be modules. Recall
that the direct product
\[ \prod_{i\in I} M_i =\{ m: I \to \bigcup_{i\in I} M_i: \: m(i) \in M \forall
i\in I\}\]
We know that 
\[ \text{Hom}_R (N, \prod_{i\in I} M_i) = \prod_{i\in I} \text{Hom}_R(N, M_i)\]
and we have the direct sum of the $M_i$
\[ \bigoplus_{i\in I} M_i =\{ m\in \prod_{i\in I}:\: m(i) = 0\text{ for all but
finitely many $i$}\}\]
and the direct sum is equal to the direct product when $I$ is finite. We have
not had to deal with infinite products very much, but we may as well talk about
them lol. for each $j \in I$, we take $\sigma_j: M_j \to \prod_{i\in I}M$ for
the map taking $m \in M_j$ to the element of the product given by
\[\sigma_j(m)(i) = \begin{cases} m & i = j \\ 0 & \text{else}\end{cases}\]
\subsubsection{Proposition.}
\begin{itemize}
\item $\sigma_j: M_j \to \prod_{i\in I} M_i$ is an injective $R$-module
homomorphism with $\sigma_j(M_j) \subseteq \bigoplus_{i\in I}M_i$
\item Denote the projection map $p_j: \prod_{i\in I}M_i \to M_j$, then we have that
$p_j \circ \sigma_k = \begin{cases}\text{id}_{m_j} & j = k \\ 0 &
\text{else}\end{cases}$
\end{itemize}
\subsubsection{Theorem.} Suppose $N$ is an $R$-module. Then there is a bijection
\[ \text{Hom}_R\left(\bigoplus_{i\in I} M_i,N\right) \to \prod_{i\in I}\text{Hom}(M_i, n)\]
given by $f \mapsto (f\circ \sigma_i)_{i\in I}$. ie. giving an $R$-module
homomorphism $f_i \oplus M_i \to N$ is the same as giving an $R$-moduls
homomorphism $f_i: M_i \to N$ for each $i\in I$. \beginproof
Suppose we have $R$-module homs $f_i: M_i \to N$ and let $m: I \to \bigcup_{i\in
I} M_i$ be an element of $\bigoplus_{i\in I} M_i$. Let's set 
\[ f(m) = \sum_{i\in I}f_i(m(i))\]
Since $m \in \bigoplus M_i$, all but finitely many of the terms are $0$, so the
sum makes sense. We need to check the following:
\[ f: \bigoplus_{i\in I} M_i \to N\] is an $R$-module hom, and that 
\[ f\circ \sigma_j = f_j\]
where $\sigma_j$ is inclusion of the $j$-th term $M_j$ into $\bigoplus_{i\in
I}M_i$, and that the maps in the theorem actually is a bijection.\vs
%
\subsection{Freedom and Cofreedom} We will first talk about cofreedom, which is not
as interesting as freedom. We will suppose that all our modules are
\textit{left} $R$-modules\vs
We know that $R$ itself is an $R$-module!\vs
Suppose $I$ is a set, and we let $M_i = R$ as an $R$-module for all 
$i\in I$. Let's set $R^I = \prod_{i\in I} M_i$, which is the set of all maps
$x:I \to R$, where $R$ acts on $R^I$ pointwise. This might be the "cofree
module" but no one cares. What's more important is the \textit{free module}
\subsubsection{Definition.} We write $R^{(I)} = \bigoplus_{i\in I} M_i$. This is
called the \textit{free} $R$-module on $I$, or the free 
$R$-module \textit{generated by $I$}\vs
For each $j \in I$ let $\sigma_j: R\to \bigoplus_{i\in I} M_i$ and we set $e_j =
\sigma_j(1)$. We know that $x\in R^{(I)}$ are officially maps $x: I\to R$ such
that $x(i) = 0 $ for all but finitely many $i$, and we therefore know that
$e_j(i) = \delta^i_j$. 
\subsubsection{Lemma.} for any $x\in R^{(I)}$, we have that \[ x = \sum_{i\in I}
x(i) e_i\]
with only finitely many terms in the sum nonzero. Then we have that $M = \langle
E \rangle$, where $E =\{e_i: \: i\in I\}$
\subsubsection{Remark.} Recall the definition of a module generated by a set: If
$M$ is an $R$-module and $S\subseteq R$ is a set, then $\langle S\rangle$ is
going to be given by 
\[ \langle S \rangle = \bigcap\{N\subset M: \: S\subseteq N, \text{ $N$ is an
$R$-submodule of $M$ }\}\]
\subsubsection{Theorem.} Suppose $N$ is an $R$-module. Then the map
$\text{Hom}_R(R^{(I)}, N) \to \text{Hom}_{\text{Set}}(I, N)$ given by $f \mapsto
(i\mapsto f(e_i))$ is a bijection of sets. That is, to give an $R$-module
homomorphism from $R^{(I)}\to N$ is the same thing as giving a map of sets
from $I\to N$ and sending the basis element $e_i$ to $f(i)$. NOTE THAT $N$ DOES
NOT HAVE TO BE FREE.\beginproof
This follows directly from the universal property of coproducts once you check
that\\ $\text{Hom}_R(R,N)$ is sort of the same as $N$, but this does also have a
direct explanation. Suppose $g: I \to N$ is a map of sets and that $x\ in
R^{(I)}$. Then we have that $x = \sum x(i)e_i$, and it looks not necessarily
finite, but all but finitely many of the terms are $0$, so it's finite. Then we
let $f(x) = \sum_{i \in I} x(i) g(i)$, and we easily prove that this is a
bijection.
\subsection{Exact Sequences} Suppose we have a sequence 
\[\hdots \to G_a \to G_{a-1} \to G_{a-2} \to \hdots \to G_{b+1} \to G_{b} \to
G_{b-1} \to \hdots\]
Where $f_{b}: G_b \to G_{b-1}$. then we say that the sequence is \textit{exact
at $b$} if $\text{Ker}(f_b) = \text{Im}(f_{b+1})$.
\subsubsection{Example.} A \textit{short exact sequence} is a sequence with
exactly 3 nonzero terms.
\section{Lecture 1}
\subsection{Some $R$-module stuff}
\subsubsection{Definition.} Suppose $M$ is an $R$-module and $S \subseteq M$. We
write $f: R^{(S)} \to M$for $R$-module hom coming from $*$. Then we say $S$ is
\textit{independent if $f$} is $1-1$. We say that $S$ is a basis if $f$ is an
isomorphism, and we say that $M$ is free if $M$ has at least one basis.
\subsubsection{Proposition.} $M$ is free if and only if $M \equiv R^{(i)}$ for
some set $I$.\vs
There are not many things to check for that proposition, so we will skip the
proof. Maybe I'll fill it in later.\vs
\subsection{Duality}
Suppose that $R$ is a ring and let $R^{op}$ be the opposite ring to $R$. Let $M$
be a left $R$-module. Then we get the \textit{dual} of $M$, denoted $M^*$ =
$\text{Hom}_{\text{$R$-mod}}(M,R)$. We will use the notation $R$-Mod for the
category of left $R$-modules and Mod-$R$ for the category of right
$R$-modules.\vs
%
Suppose $r\in R$ and $\lambda \in D(M)$. Define $(\lambda r) (m) = \lambda(m)r$.
Then we have that $\lambda r \in D(m)$ and the map $D(m) \times R \to D(m)$
given by $(\lambda, r) \mapsto \lambda r$ makes $D(M)$ into a right
$R$-module\vs
remember that we showed that $R$-modules was enriched over $Z(R)$-mod. It is
clear that $\lambda r: M \to M$ is a group homomorphism. We just have to show
that it commutes with the action of $R$ on $M$. But this will come from the
basic fact that left and right actions commute. eg. all we have to do is check
that $\lambda r$ is in $D(M)$, which can be done by showing that if $m \in M,
s \in R$, then $\lambda r (sm) = s (\lambda r)(m)$. But we just compute 
\[ \lambda r (sm) = \lambda(sm)r = s(\lambda(m)r) = s(\lambda r)(m)\]
So we get a map
\[ D: \text{$R$-Mod} \to \text{Mod-$R$}\]
by 
\[ M \mapsto D(M)\]
or equivalently, we have that $D$ is a functor from $(R-\text{Mod})^{op} \to
\text{$R^{op}$-Mod}$
\subsubsection{Proposition.} $D: \text{$R$-Mod} \to \text{Mod-$R$}$ is a
contravariant functor between the two categories.\vs
Recall the definition of a contravariant functor: For two categories $C$ and
$D$, then a (covariant) functor $F: C\to D$ is a pair of maps $\text{Obj}(F):
\text{Obj}(C)\to \text{Obj}(D)$, and for each $X,Y$ in $\text{Obj}(C)$, then
we get that the map $F: \text{Hom}_C(X,Y) \to \text{Hom}_D(F(X), F(Y))$
where we have that composition of maps is preserved. A contravariant functor is
a covariant functor from $C^{op}\to D$. Then we can reason about whatever else.
You essentially can take a "functor" from $C$ to $D$, but flip the arrows in the
information preservation part.\vs
Anyways, we can talk about the proof of the theorem. Suppose that $\alpha: M \to
N$ is a map of $R$-modules. Then we get a map $F(\alpha): D(N) \to D(M) =
\text{Hom}_R(N,R) \to \text{Hom}_R(M,R)$ given by $f \mapsto f\circ \alpha$.
Then all we have to do is check that the map $\alpha^*$ is a morphism in
$R^{op}$-Mod. Checking this is just a bunch of "moving parentheses around",
which we will not do in class but I might fill in the details later.\vs
%
We know what $D$ does on $R$, we know that $D(R) \equiv R$ as a right
$R$-module. In fact, the map $D(R) = \text{Hom}_{\text{$R$-Mod}}(R,R)$ by
$\lambda \mapsto \lambda(1)$ is an isomorphism of right $R$-Modules. For
instance, we can tell you what the inverse is. We can define $\phi_R: R\to R$ by
$\phi_R(s) = sr$, and it's easy to check that $\phi_s \in D(R)$, and that
$ev(\phi_s) = s, \phi(ev(\lambda)) = \lambda$.
\subsubsection{Corollary.} $D(R^{(S)}) \equiv R^S$ as a right $R$-Module. In
particular, if $S$ is finite, then $D(R^{(S)}) \equiv R^{(S)}$.\vs
This is apparent from thm. 0.1.2. The fact that this map is also a map of
$R$-Modules is just moving parentheses around.
\subsection{Two Theorems}
We are going to prove two theorems that are related to each other, but seem
unrelated at first.
\subsubsection{Theorem (classification of finitely generated modules over a
PID).} Suppose $M$ is a finitely generated $R$-Module over a PID $R$. Then there
exists a sequence 
\[ d_1 | d_2 | \hdots | d_r\]
non-unit elements of $R$ such that
\[ M \equiv \bigoplus_{i \in 1\hdots r} \frac{R}{d_iR}\]
Furthermore, this sequence is unique up to unit.
\subsubsection{Theorem.} If $R$ is a UFD, then so is $R[x]$. \vs
These two theorems have the "same" proof. The weird problem on the homework
about the generalization of the gcd is related to these two theorems. The second
theorem is also called "Gauss's Lemma". He only proved it for the integers, but
what he wrote happened to be the proof of this theorem.\vs
You can reduce this to an algorithm to reducing a matrix to a diagonal matrix
that has certain properties. The proof is essentially equivalent is to make
matrices into JCF. But matrices of polynomials are really hard to do without
making mistakes. Computers can do this pretty easily, though, you should do this
in sagemath.
\section{Lecture 14}
\subsection{Some Facts of Life}
We want to prove the two theorems from earlier. To start, let's consider $R$ an integral domain, and
$S$ a subset of $R$, then we want to define the \text{GCD} and LCM for any subset of
$R$. \vs
set \[CD(S) =\{ x \in R: \: \forall s\in S \: x | s\}\]. Then set 
\[
CM(S) =\{ x\in R: \: \forall s\in S \: s | x\}
\]
Then we take 
\[\text{GCD}(S) = CD(S) \cap CM(CD(S))\]
and \[ LCM(S) = CM(S) \cap CD(CM(S))\]
We know that if $\text{GCD}(S)$ is not empty, it consists of one equivalence class of
associates. The same is true for LCM. We also know that if $a,b \in R\setminus
\{ 0\}$, then  $gcd(a,b) \in \text{GCD}(\{a,b\} )$. Furthermore, if $R$ is a UFD, then
the \text{GCD} and LCM sets are nonempty for any subset $S \subseteq R$. Also, if $d
\in \text{GCD}(S)$, and $R$ is a UFD, then $dR$ contains $\sum_{x\in S}Rx$, with
equality holding if and only if $R$ is a PID.\vs
Note that by "associates" we just mean multiplication by a unit, or the
equivalence class of the relation $a \sim b \leftrightarrow ua = b$ for $u$ a
unit. \vs
If  $R$ is a UFD, and $d\in LCM(S)$, then $dR = \bigcap_{s\in S}Rs$.\vs
We will prove all of these things on the homework. Note that the \text{GCD} of
$\varnothing$ is just $\{0\}$, and you can verify this pretty easily by
understanding that the $CD $ of the empty set is $R$, and the common multiple
set of $R$ is just $\{0\}$. 
\subsubsection{Lemma.} Suppose that $S \subseteq R$ and $R$ is an integral
domain. Then 
\[
CD(S) = CD\left(\sum_{s\in S}Rs\right)
\]
The proof is "obvious" but I will verify this later.
\subsection{Primitivity and Content}
Suppose $R$ is an integral domain.
\subsubsection{Definition.}  IF $S \subseteq R$, then we say that $S$ is
\textit{primitive} if for every principal prime ideal $P = pR$ in $R$, there
exists some $s \in S\setminus P$\vs
If you have this definition, but replace \textit{principal prime} with
\textit{prime}, then you get that this is an equivalent condition to "$S$
generates $R$". 
\subsection{Proposition.} Suppose $R$ is a UFD. Then $S\subseteq R$ is primitive
$\iff$ $1 \in \text{GCD}(S)$. \beginproof
Pick a set $\Sigma \subseteq R$ of representatives of the irreducibles in $R$.
That is, every element irreducible element of $R$ is an associate of exactly one element of
$\Sigma$.
If $1 \in \text{GCD}(S)$, then for every $q \in \Sigma$, there has to be some $s\in S$
such that $q \not | s$, (otherwise, $q$ would divide all the $s's$, but $1$ is
not a multiple of $q$, so we know that $1$ would not be in the $\text{GCD}$). Since $q$
is irreducible, $qR$ is a principal prime ideal (as $R$ is a UFD), this shows
that $S$ is primitive if $q \in \text{GCD}(S)$.\vs
On the other hand, suppose $S$ is primitive. then we just reverse the steps that
we did before. Let $q \in \Sigma$, then there exists some $s\not\in qR$. So
$q\not | s$. So if $d \in \text{GCD}(S)$, and $q \not| d$. Therefore the elements of
the $\text{GCD}(S)$ are not divisible by any irreducibles, so (as $R$ is a UFD), they
have to be units.
\subsubsection{Definition.} Suppose $R$ is an integral domain and $F$ is a free
$R$-module. Suppose $x \in F$. We say that $x$ is \textit{primitive} if
for every primcipal prime ideal $P = pR$, there exists a $\lambda \in F^*$
such that $x\not \in P$. \vs
The content ideal of $x$, denoted $C_F(x) =\{\lambda(x): \lambda \in F^*\}$\vs
Note that we didn't choose a basis for this definition, nor did it depend on a
choice of irreducibles.\vs
Note that in this definition, we are saying that the content ideal is a subset
of $R$, since we are taking a set of $\lambda(x)$, which pair to get a guy in
$R$.
\subsubsection{Proposition.} Suppose $F = R^{(I)}$ is free and $x =
\sum_ix_ie_i$ is in $F$. Then 
\begin{itemize}
\item $C_F(s) = \sum_{i\in I}x_iR$.
\item $x$ is primitive if and only if $\{x_i\}$ is primitive.
\item $1 \in \text{GCD}(C_F(x))$ implies that $x$ is primitive.
\end{itemize}  
\text{}
\beginproof First note that $C_F(x)$ is an ideal. To see the frist part, note
that $\lambda(x)$, $\mu(x) \in C_F(x)$, then $\lambda(x) - \mu(x) \in C_F(x)$.
Then $r \in R$, $\lambda(x) \in C_F(x) \implies (r\lambda)(x) - r(\lambda(x))
\in C_F(x)$
\end{document}
